{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec\n",
    "here I implement word2vec with very simple example using tensorflow  \n",
    "word2vec is vector representation for words with similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Data\n",
    "we will use only 10 sentences to create word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ['king is a strong man', \n",
    "          'queen is a wise woman', \n",
    "          'boy is a young man',\n",
    "          'girl is a young woman',\n",
    "          'prince is a young king',\n",
    "          'princess is a young queen',\n",
    "          'man is strong', \n",
    "          'woman is pretty',\n",
    "          'prince is a boy will be king',\n",
    "          'princess is a girl will be queen']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove stop words\n",
    "In order for efficiency of creating word vector, we will remove commonly used words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(corpus):\n",
    "    stop_words = ['is', 'a', 'will', 'be']\n",
    "    results = []\n",
    "    for text in corpus:\n",
    "        tmp = text.split(' ')\n",
    "        for stop_word in stop_words:\n",
    "            if stop_word in tmp:\n",
    "                tmp.remove(stop_word)\n",
    "        results.append(\" \".join(tmp))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = remove_stop_words(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for text in corpus:\n",
    "    for word in text.split(' '):\n",
    "        words.append(word)\n",
    "\n",
    "words = set(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we have word set by which we will have word vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boy',\n",
       " 'girl',\n",
       " 'king',\n",
       " 'man',\n",
       " 'pretty',\n",
       " 'prince',\n",
       " 'princess',\n",
       " 'queen',\n",
       " 'strong',\n",
       " 'wise',\n",
       " 'woman',\n",
       " 'young'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data generation\n",
    "we will generate label for each word using skip gram.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : woman : <enumerate object at 0x7fee34fa4f30>\n",
      "1 : king : <enumerate object at 0x7fee34fa4f30>\n",
      "2 : girl : <enumerate object at 0x7fee34fa4f30>\n",
      "3 : prince : <enumerate object at 0x7fee34fa4f30>\n",
      "4 : pretty : <enumerate object at 0x7fee34fa4f30>\n",
      "5 : young : <enumerate object at 0x7fee34fa4f30>\n",
      "6 : wise : <enumerate object at 0x7fee34fa4f30>\n",
      "7 : queen : <enumerate object at 0x7fee34fa4f30>\n",
      "8 : boy : <enumerate object at 0x7fee34fa4f30>\n",
      "9 : strong : <enumerate object at 0x7fee34fa4f30>\n",
      "10 : man : <enumerate object at 0x7fee34fa4f30>\n",
      "11 : princess : <enumerate object at 0x7fee34fa4f30>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x=enumerate(words)\n",
    "for i, key in x:\n",
    "    print(i, \":\", key, \":\", x)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2int = {}\n",
    "\n",
    "for i,word in enumerate(words):\n",
    "    word2int[word] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for sentence in corpus:\n",
    "    sentences.append(sentence.split())\n",
    "    \n",
    "WINDOW_SIZE = 2\n",
    "\n",
    "data = []\n",
    "for sentence in sentences:\n",
    "    for idx, word in enumerate(sentence):\n",
    "        for neighbor in sentence[max(idx - WINDOW_SIZE, 0) : min(idx + WINDOW_SIZE, len(sentence)) + 1] : \n",
    "            if neighbor != word:\n",
    "                data.append([word, neighbor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "king strong man\n",
      "queen wise woman\n",
      "boy young man\n",
      "girl young woman\n",
      "prince young king\n",
      "princess young queen\n",
      "man strong\n",
      "woman pretty\n",
      "prince boy king\n",
      "princess girl queen\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "for text in corpus:\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>king</td>\n",
       "      <td>strong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>king</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>strong</td>\n",
       "      <td>king</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>strong</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>man</td>\n",
       "      <td>king</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>man</td>\n",
       "      <td>strong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>queen</td>\n",
       "      <td>wise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>queen</td>\n",
       "      <td>woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>wise</td>\n",
       "      <td>queen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>wise</td>\n",
       "      <td>woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>woman</td>\n",
       "      <td>queen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>woman</td>\n",
       "      <td>wise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>boy</td>\n",
       "      <td>young</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>boy</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>young</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>young</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>man</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>man</td>\n",
       "      <td>young</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>girl</td>\n",
       "      <td>young</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>girl</td>\n",
       "      <td>woman</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     input   label\n",
       "0     king  strong\n",
       "1     king     man\n",
       "2   strong    king\n",
       "3   strong     man\n",
       "4      man    king\n",
       "5      man  strong\n",
       "6    queen    wise\n",
       "7    queen   woman\n",
       "8     wise   queen\n",
       "9     wise   woman\n",
       "10   woman   queen\n",
       "11   woman    wise\n",
       "12     boy   young\n",
       "13     boy     man\n",
       "14   young     boy\n",
       "15   young     man\n",
       "16     man     boy\n",
       "17     man   young\n",
       "18    girl   young\n",
       "19    girl   woman"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data, columns = ['input', 'label'])\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 2)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'woman': 0,\n",
       " 'king': 1,\n",
       " 'girl': 2,\n",
       " 'prince': 3,\n",
       " 'pretty': 4,\n",
       " 'young': 5,\n",
       " 'wise': 6,\n",
       " 'queen': 7,\n",
       " 'boy': 8,\n",
       " 'strong': 9,\n",
       " 'man': 10,\n",
       " 'princess': 11}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Tensorflow Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "ONE_HOT_DIM = len(words)\n",
    "\n",
    "# function to convert numbers to one hot vectors\n",
    "def to_one_hot_encoding(data_point_index):\n",
    "    one_hot_encoding = np.zeros(ONE_HOT_DIM)\n",
    "    one_hot_encoding[data_point_index] = 1\n",
    "    return one_hot_encoding\n",
    "\n",
    "X = [] # input word\n",
    "Y = [] # target word\n",
    "\n",
    "for x, y in zip(df['input'], df['label']):\n",
    "    X.append(to_one_hot_encoding(word2int[ x ]))\n",
    "    Y.append(to_one_hot_encoding(word2int[ y ]))\n",
    "\n",
    "# convert them to numpy arrays\n",
    "X_train = np.asarray(X)\n",
    "Y_train = np.asarray(Y)\n",
    "\n",
    "# making placeholders for X_train and Y_train\n",
    "x = tf.placeholder(tf.float32, shape=(None, ONE_HOT_DIM))\n",
    "y_label = tf.placeholder(tf.float32, shape=(None, ONE_HOT_DIM))\n",
    "\n",
    "# word embedding will be 2 dimension for 2d visualization\n",
    "EMBEDDING_DIM = 2 \n",
    "\n",
    "# hidden layer: which represents word vector eventually\n",
    "W1 = tf.Variable(tf.random_normal([ONE_HOT_DIM, EMBEDDING_DIM]))\n",
    "b1 = tf.Variable(tf.random_normal([1])) #bias\n",
    "hidden_layer = tf.add(tf.matmul(x,W1), b1)\n",
    "\n",
    "# output layer\n",
    "W2 = tf.Variable(tf.random_normal([EMBEDDING_DIM, ONE_HOT_DIM]))\n",
    "b2 = tf.Variable(tf.random_normal([1]))\n",
    "prediction = tf.nn.softmax(tf.add( tf.matmul(hidden_layer, W2), b2))\n",
    "\n",
    "# loss function: cross entropy\n",
    "loss = tf.reduce_mean(-tf.reduce_sum(y_label * tf.log(prediction), axis=[1]))\n",
    "\n",
    "# training operation\n",
    "train_op = tf.train.GradientDescentOptimizer(0.05).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 loss is :  3.0540948\n",
      "iteration 3000 loss is :  1.8409148\n",
      "iteration 6000 loss is :  1.7943476\n",
      "iteration 9000 loss is :  1.7750227\n",
      "iteration 12000 loss is :  1.7583953\n",
      "iteration 15000 loss is :  1.7460406\n",
      "iteration 18000 loss is :  1.7376893\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init) \n",
    "\n",
    "iteration = 20000\n",
    "for i in range(iteration):\n",
    "    # input is X_train which is one hot encoded word\n",
    "    # label is Y_train which is one hot encoded neighbor word\n",
    "    sess.run(train_op, feed_dict={x: X_train, y_label: Y_train})\n",
    "    if i % 3000 == 0:\n",
    "        print('iteration '+str(i)+' loss is : ', sess.run(loss, feed_dict={x: X_train, y_label: Y_train}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.15919054 -0.59321797]\n",
      " [ 0.4451306   1.064285  ]\n",
      " [ 2.9968534  -0.7712728 ]\n",
      " [ 3.4498668   3.3069115 ]\n",
      " [ 4.4901257  -0.8109044 ]\n",
      " [ 0.33018768  0.09246325]\n",
      " [ 5.775937   -2.2609    ]\n",
      " [ 0.8598887  -0.43246448]\n",
      " [ 1.70013     2.31086   ]\n",
      " [ 3.407745    6.8012514 ]\n",
      " [ 0.16647351  0.7868867 ]\n",
      " [ 2.0699794  -1.2199274 ]]\n"
     ]
    }
   ],
   "source": [
    "# Now the hidden layer (W1 + b1) is actually the word look up table\n",
    "vectors = sess.run(W1 + b1)\n",
    "print(vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word vector in table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>woman</td>\n",
       "      <td>0.159191</td>\n",
       "      <td>-0.593218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>king</td>\n",
       "      <td>0.445131</td>\n",
       "      <td>1.064285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>girl</td>\n",
       "      <td>2.996853</td>\n",
       "      <td>-0.771273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>prince</td>\n",
       "      <td>3.449867</td>\n",
       "      <td>3.306911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pretty</td>\n",
       "      <td>4.490126</td>\n",
       "      <td>-0.810904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>young</td>\n",
       "      <td>0.330188</td>\n",
       "      <td>0.092463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wise</td>\n",
       "      <td>5.775937</td>\n",
       "      <td>-2.260900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>queen</td>\n",
       "      <td>0.859889</td>\n",
       "      <td>-0.432464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>boy</td>\n",
       "      <td>1.700130</td>\n",
       "      <td>2.310860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>strong</td>\n",
       "      <td>3.407745</td>\n",
       "      <td>6.801251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>man</td>\n",
       "      <td>0.166474</td>\n",
       "      <td>0.786887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>princess</td>\n",
       "      <td>2.069979</td>\n",
       "      <td>-1.219927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word        x1        x2\n",
       "0      woman  0.159191 -0.593218\n",
       "1       king  0.445131  1.064285\n",
       "2       girl  2.996853 -0.771273\n",
       "3     prince  3.449867  3.306911\n",
       "4     pretty  4.490126 -0.810904\n",
       "5      young  0.330188  0.092463\n",
       "6       wise  5.775937 -2.260900\n",
       "7      queen  0.859889 -0.432464\n",
       "8        boy  1.700130  2.310860\n",
       "9     strong  3.407745  6.801251\n",
       "10       man  0.166474  0.786887\n",
       "11  princess  2.069979 -1.219927"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_df = pd.DataFrame(vectors, columns = ['x1', 'x2'])\n",
    "w2v_df['word'] = words\n",
    "w2v_df = w2v_df[['word', 'x1', 'x2']]\n",
    "w2v_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word vector in 2d chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for word, x1, x2 in zip(w2v_df['word'], w2v_df['x1'], w2v_df['x2']):\n",
    "    ax.annotate(word, (x1,x2 ))\n",
    "    \n",
    "PADDING = 1.0\n",
    "x_axis_min = np.amin(vectors, axis=0)[0] - PADDING\n",
    "y_axis_min = np.amin(vectors, axis=0)[1] - PADDING\n",
    "x_axis_max = np.amax(vectors, axis=0)[0] + PADDING\n",
    "y_axis_max = np.amax(vectors, axis=0)[1] + PADDING\n",
    " \n",
    "plt.xlim(x_axis_min,x_axis_max)\n",
    "plt.ylim(y_axis_min,y_axis_max)\n",
    "plt.rcParams[\"figure.figsize\"] = (5,5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
